parent: research/conditional/train/configs/baselines/gpt/small.yaml
md5_parent_hash: cbdf4e5992f41713488c25c819086e51
interactive_debug: false
time: 00:10:00
n_gpus: 1

params:
    ^group_size: [2,4,8,16,32,64,128,256]
    ^gradient_checkpointing: [true,false]
    ^batch_size: [2,4,8,16,32,64,128,256]

    flash_attention: true
    n_steps: 3
    learning_rate: 2e-3
    n_experts: 512
    ff_mode: cont_moe
    flop_matched: true
    sparsity_dim: 0
    temperature: 1.0
    name: memory_usage_grid_small
    tags: [MoT, memory, small]
    loss_checkpoint_chungs: 64
    decoding_interval: 0
    save_weights_interval: 0
    logging_interval_heavy: 100000000000

    use_dummy_dataset: true

    init_type: "kaiming_uniform"
    init_scale: 1.0

    gpu_usage_report_path: "results_small.json"
    gpu_usage_report_params: "dmodel,dff,n_blocks,n_att_heads,group_size,gradient_checkpointing,batch_size"