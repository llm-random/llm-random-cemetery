{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.rand(512, 256)/256\n",
    "\n",
    "w = torch.rand(512)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5033, 0.4804, 0.5342, 0.5053, 0.4966, 0.5117, 0.5022, 0.4802, 0.5121,\n",
       "        0.4804, 0.4846, 0.5027, 0.4738, 0.4745, 0.4981, 0.5016, 0.4807, 0.4858,\n",
       "        0.4865, 0.5107, 0.4755, 0.4935, 0.5141, 0.4929, 0.4851, 0.5248, 0.4940,\n",
       "        0.4823, 0.4859, 0.5086, 0.4724, 0.4551, 0.5041, 0.5080, 0.5092, 0.4751,\n",
       "        0.4703, 0.4927, 0.4960, 0.5154, 0.5149, 0.4930, 0.5147, 0.4610, 0.4845,\n",
       "        0.5002, 0.4931, 0.5099, 0.4899, 0.4943, 0.4507, 0.4848, 0.4843, 0.4813,\n",
       "        0.5334, 0.5046, 0.4967, 0.4850, 0.4928, 0.5149, 0.4935, 0.4820, 0.4793,\n",
       "        0.4816, 0.4909, 0.5130, 0.4945, 0.4833, 0.4999, 0.5076, 0.4917, 0.4705,\n",
       "        0.5074, 0.4879, 0.5020, 0.5070, 0.4933, 0.4964, 0.4834, 0.4865, 0.5050,\n",
       "        0.4806, 0.4841, 0.5149, 0.5076, 0.4956, 0.5046, 0.4901, 0.5033, 0.4744,\n",
       "        0.5045, 0.4969, 0.4817, 0.5094, 0.5163, 0.5032, 0.5003, 0.5077, 0.4642,\n",
       "        0.4971, 0.5078, 0.4890, 0.4836, 0.4921, 0.4811, 0.4992, 0.4875, 0.4920,\n",
       "        0.5111, 0.4764, 0.5050, 0.5056, 0.5053, 0.4864, 0.4882, 0.4791, 0.5284,\n",
       "        0.4903, 0.4961, 0.5027, 0.5154, 0.5114, 0.5076, 0.5055, 0.5143, 0.4846,\n",
       "        0.5114, 0.5089, 0.5142, 0.5052, 0.5073, 0.5038, 0.4770, 0.4955, 0.5059,\n",
       "        0.4973, 0.4923, 0.4997, 0.4611, 0.5150, 0.5153, 0.4984, 0.4784, 0.4892,\n",
       "        0.4982, 0.4755, 0.4840, 0.5111, 0.4915, 0.4986, 0.4896, 0.4669, 0.4984,\n",
       "        0.4951, 0.4881, 0.5179, 0.4989, 0.4947, 0.5028, 0.4960, 0.5015, 0.4826,\n",
       "        0.4988, 0.4888, 0.4696, 0.4515, 0.4907, 0.4861, 0.5143, 0.4894, 0.4839,\n",
       "        0.5131, 0.5019, 0.5124, 0.5127, 0.4916, 0.5171, 0.4995, 0.4855, 0.5327,\n",
       "        0.5062, 0.4674, 0.5075, 0.4872, 0.4796, 0.4883, 0.4695, 0.4788, 0.5035,\n",
       "        0.4810, 0.4789, 0.4747, 0.5301, 0.5217, 0.4837, 0.4949, 0.5001, 0.5244,\n",
       "        0.4607, 0.4978, 0.5031, 0.4852, 0.5098, 0.4846, 0.4540, 0.4949, 0.4969,\n",
       "        0.4730, 0.5117, 0.5070, 0.4958, 0.4899, 0.5101, 0.4936, 0.5028, 0.4961,\n",
       "        0.4823, 0.4808, 0.4946, 0.5199, 0.4850, 0.5063, 0.4897, 0.5049, 0.5043,\n",
       "        0.4862, 0.4933, 0.4892, 0.4854, 0.4993, 0.5094, 0.4930, 0.4854, 0.4945,\n",
       "        0.5037, 0.5055, 0.5007, 0.5331, 0.5069, 0.4936, 0.5138, 0.4897, 0.4857,\n",
       "        0.4955, 0.4881, 0.4998, 0.5007, 0.5074, 0.4972, 0.4887, 0.5098, 0.4950,\n",
       "        0.4785, 0.4814, 0.4961, 0.4811])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(w@p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 1024])\n"
     ]
    }
   ],
   "source": [
    "p = torch.rand(512, 256)/256\n",
    "pz = torch.zeros(512, 256)\n",
    "\n",
    "# p = torch.rand(1, 2)\n",
    "# pz = torch.zeros(1, 2)\n",
    "\n",
    "projection_4 = torch.concat(\n",
    "    (torch.concat((p, pz, pz, pz), dim=0),\n",
    "    torch.concat((pz, p, pz, pz), dim=0),\n",
    "    torch.concat((pz, pz, p, pz), dim=0),\n",
    "    torch.concat((pz, pz, pz, p), dim=0),)\n",
    ", dim=1)\n",
    "# projection_4 = torch.concat((projection_4, projection_4, projection_4, projection_4), dim=1)\n",
    "print(projection_4.shape)\n",
    "\n",
    "w = torch.rand(2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 2048])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2048])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_4.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0005, 0.0019, 0.0003,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0029, 0.0013, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0026, 0.0007, 0.0024,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0038, 0.0022, 0.0007],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0012, 0.0002, 0.0038],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0018, 0.0027, 0.0002]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x2048 and 1024x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;129;43m@projection_4\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x2048 and 1024x2048)"
     ]
    }
   ],
   "source": [
    "(w.T@projection_4.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(27)\n",
    "\n",
    "# Example tensor of shape (1, 1, H, W)\n",
    "DIM = 4\n",
    "W = torch.rand(DIM, DIM)\n",
    "P1 = torch.rand(int(DIM/2), DIM)\n",
    "P2 = torch.rand(DIM, int(DIM/2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5872, 1.1626, 1.6426, 0.9742],\n",
       "        [0.4341, 0.6854, 0.8121, 0.5155]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1@W#@P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.rand([100, 256])\n",
    "p1 = torch.rand([512, 256]) #P torch.Size([256, 512])\n",
    "w = torch.rand([1536, 512]) #W torch.Size([256, 1536])\n",
    "p2 = torch.rand([768, 1536]) #P torch.Size([256, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(i@p1.T@w.T@p2.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM1 = 12\n",
    "DIM2 = 4\n",
    "W = torch.rand(DIM1, DIM2)\n",
    "P1 = torch.rand(int(DIM1/2), DIM1)\n",
    "P2 = torch.rand(DIM2, int(DIM2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4])\n",
      "torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.6443, 5.0776],\n",
       "        [6.5575, 5.7987],\n",
       "        [7.7880, 7.0714],\n",
       "        [7.1346, 6.4522],\n",
       "        [6.2099, 5.7591],\n",
       "        [7.6796, 6.9450]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = P1@W@P2\n",
    "print(W.shape)\n",
    "print(r.shape)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM1 = 50257\n",
    "DIM2 = 512\n",
    "W = torch.rand(DIM1, DIM2)\n",
    "P2 = torch.rand(DIM2, int(DIM2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([502, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W@P2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6864, 0.3059],\n",
       "        [0.6783, 0.0089],\n",
       "        [0.8684, 0.8320],\n",
       "        [0.6172, 0.5390],\n",
       "        [0.8979, 0.8956]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb = 512\n",
    "# yb = 2048\n",
    "# xs = 256\n",
    "# ys = 1024\n",
    "# W = torch.rand(xb, yb)\n",
    "# P1 = torch.rand(xs, xb)\n",
    "# P2 = torch.rand(yb, ys)\n",
    "\n",
    "# r = P1@W@P2\n",
    "# print(W.shape)\n",
    "# print(r.shape)\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=8, bias=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lizrd.core.misc import Linear\n",
    "\n",
    "\n",
    "l = Linear(\n",
    "    4, #xs\n",
    "    8, #xb\n",
    "    init_type = \"kaiming_uniform\",\n",
    "    init_scale = 1.0\n",
    ")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (902681333.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Attention\":\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "# from lizrd.train.train_utils import get_model\n",
    "# from research.conditional.utils.model_utils import get_ff_layer\n",
    "# from research.projected_distillation.llm import ProjectedFeedForward\n",
    "# dmodel = 256\n",
    "# dff = 1024\n",
    "# projected_dmodel = dmodel*2\n",
    "# projected_dff = dff*2\n",
    "# n_blocks = 8\n",
    "# init_type = \"kaiming_uniform\"\n",
    "# init_scale= 1.0\n",
    "# block_modules = {\n",
    "#     \"FF\": lambda: ProjectedFeedForward(\n",
    "#             dmodel, dff, projected_dmodel, projected_dff, init_type=init_type, init_scale= init_scale\n",
    "#         ),\n",
    "#     \"Attention\": \n",
    "# }\n",
    "\n",
    "# model = get_model(\n",
    "#         max_length=256,\n",
    "#         vocab_size=50048,\n",
    "#         block_modules=block_modules,\n",
    "#         dm=dmodel,\n",
    "#         n_blocks=n_blocks,\n",
    "#         device=(\n",
    "#             torch.device(\"cuda\")\n",
    "#         ),  # in case of  DDP/FSDP, we initialize the model on CPU and move it to the GPU later\n",
    "#         init_type=init_type,\n",
    "#         init_scale=init_scale,\n",
    "#         ddp_enabled=False,\n",
    "#         fsdp_enabled=False,\n",
    "#         fsdp_param_precision=False,\n",
    "#         fsdp_mixed_precision_ignore_classes=False,\n",
    "#         fsdp_offload_params=False,\n",
    "#         fsdp_min_num_params=False,\n",
    "#         fsdp_modules_to_wrap=False,\n",
    "#         activation_checkpointing_modules=False,\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "randomllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
