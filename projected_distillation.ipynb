{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(27)\n",
    "\n",
    "# Example tensor of shape (1, 1, H, W)\n",
    "DIM = 4\n",
    "W = torch.rand(DIM, DIM)\n",
    "P1 = torch.rand(int(DIM/2), DIM)\n",
    "P2 = torch.rand(DIM, int(DIM/2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5872, 1.1626, 1.6426, 0.9742],\n",
       "        [0.4341, 0.6854, 0.8121, 0.5155]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1@W#@P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM1 = 12\n",
    "DIM2 = 4\n",
    "W = torch.rand(DIM1, DIM2)\n",
    "P1 = torch.rand(int(DIM1/2), DIM1)\n",
    "P2 = torch.rand(DIM2, int(DIM2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4])\n",
      "torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.6443, 5.0776],\n",
       "        [6.5575, 5.7987],\n",
       "        [7.7880, 7.0714],\n",
       "        [7.1346, 6.4522],\n",
       "        [6.2099, 5.7591],\n",
       "        [7.6796, 6.9450]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = P1@W@P2\n",
    "print(W.shape)\n",
    "print(r.shape)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = 512\n",
    "yb = 2048\n",
    "xs = 256\n",
    "ys = 1024\n",
    "W = torch.rand(xb, yb)\n",
    "P1 = torch.rand(xs, xb)\n",
    "P2 = torch.rand(yb, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 2048])\n",
      "torch.Size([256, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[130796.1172, 128785.4453, 129663.6562,  ..., 128499.3594,\n",
       "         130298.6484, 129971.3906],\n",
       "        [133012.6562, 130936.7422, 131843.7656,  ..., 130729.7422,\n",
       "         132476.1875, 132249.2500],\n",
       "        [129721.0234, 127680.9062, 128570.0000,  ..., 127446.5781,\n",
       "         129220.4062, 128920.0234],\n",
       "        ...,\n",
       "        [130213.5469, 128230.0234, 129112.5391,  ..., 127997.6562,\n",
       "         129677.8828, 129393.8047],\n",
       "        [130767.9375, 128707.3594, 129624.9375,  ..., 128489.2734,\n",
       "         130267.7734, 129968.9062],\n",
       "        [132819.5938, 130733.5156, 131616.2812,  ..., 130468.2188,\n",
       "         132302.6875, 132004.3594]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = P1@W@P2\n",
    "print(W.shape)\n",
    "print(r.shape)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=8, bias=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lizrd.core.misc import Linear\n",
    "\n",
    "\n",
    "l = Linear(\n",
    "    4, #xs\n",
    "    8, #xb\n",
    "    init_type = \"kaiming_uniform\",\n",
    "    init_scale = 1.0\n",
    ")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1175, -0.3492, -0.1019,  0.3333],\n",
       "        [ 0.6530,  0.1067,  0.2894,  0.6535],\n",
       "        [-0.6010,  0.2718, -0.0290,  0.3961],\n",
       "        [ 0.8392,  0.4242, -0.7526,  0.2545],\n",
       "        [-0.8204,  0.8378, -0.7909,  0.1884],\n",
       "        [-0.8179,  0.0868,  0.5423, -0.1861],\n",
       "        [-0.5960, -0.3729, -0.1753, -0.1666],\n",
       "        [-0.6087,  0.0211,  0.4279,  0.2998]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lizrd.train.train_utils import get_model\n",
    "\n",
    "\n",
    "model = get_model(\n",
    "        max_length=256,\n",
    "        vocab_size=50048,\n",
    "        block_modules=block_modules,\n",
    "        dm=args.dmodel,\n",
    "        n_blocks=args.n_blocks,\n",
    "        device=(\n",
    "            torch.device(\"cpu\") if data_distributed else DEVICE\n",
    "        ),  # in case of  DDP/FSDP, we initialize the model on CPU and move it to the GPU later\n",
    "        init_type=args.init_type,\n",
    "        init_scale=args.init_scale,\n",
    "        ddp_enabled=args.ddp_enabled,\n",
    "        fsdp_enabled=args.fsdp_enabled,\n",
    "        fsdp_param_precision=fsdp_param_precision,\n",
    "        fsdp_mixed_precision_ignore_classes=fsdp_mixed_precision_ignore_classes,\n",
    "        fsdp_offload_params=args.fsdp_offload_params,\n",
    "        fsdp_min_num_params=args.fsdp_min_num_params,\n",
    "        fsdp_modules_to_wrap=fsdp_modules_to_wrap,\n",
    "        activation_checkpointing_modules=activation_checkpointing_modules,\n",
    "        model_fragmentation=args.model_parallelism_fragmentation,\n",
    "        residual_fn=residual_fn,\n",
    "        is_logging_process=is_logging_process,\n",
    "        local_rank=local_rank,\n",
    "        include_positional_embedding=(not args.no_positional_embedding)\n",
    "        and (args.attention_mode != \"rope\"),\n",
    "        checkpoint=checkpoint,\n",
    "        projected_distillation = args.projected_distillation\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmrandom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
