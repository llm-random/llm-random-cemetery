{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 1024])\n"
     ]
    }
   ],
   "source": [
    "p = torch.rand(512, 256)/256\n",
    "pz = torch.zeros(512, 256)\n",
    "\n",
    "# p = torch.rand(1, 2)\n",
    "# pz = torch.zeros(1, 2)\n",
    "\n",
    "projection_4 = torch.concat(\n",
    "    (torch.concat((p, pz, pz, pz), dim=0),\n",
    "    torch.concat((pz, p, pz, pz), dim=0),\n",
    "    torch.concat((pz, pz, p, pz), dim=0),\n",
    "    torch.concat((pz, pz, pz, p), dim=0),)\n",
    ", dim=1)\n",
    "# projection_4 = torch.concat((projection_4, projection_4, projection_4, projection_4), dim=1)\n",
    "print(projection_4.shape)\n",
    "\n",
    "w = torch.rand(2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 2048])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2048])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_4.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0005, 0.0019, 0.0003,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0029, 0.0013, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0026, 0.0007, 0.0024,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0038, 0.0022, 0.0007],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0012, 0.0002, 0.0038],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0018, 0.0027, 0.0002]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x2048 and 1024x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;129;43m@projection_4\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x2048 and 1024x2048)"
     ]
    }
   ],
   "source": [
    "(w.T@projection_4.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(27)\n",
    "\n",
    "# Example tensor of shape (1, 1, H, W)\n",
    "DIM = 4\n",
    "W = torch.rand(DIM, DIM)\n",
    "P1 = torch.rand(int(DIM/2), DIM)\n",
    "P2 = torch.rand(DIM, int(DIM/2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5872, 1.1626, 1.6426, 0.9742],\n",
       "        [0.4341, 0.6854, 0.8121, 0.5155]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1@W#@P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.rand([100, 256])\n",
    "p1 = torch.rand([512, 256]) #P torch.Size([256, 512])\n",
    "w = torch.rand([1536, 512]) #W torch.Size([256, 1536])\n",
    "p2 = torch.rand([768, 1536]) #P torch.Size([256, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(i@p1.T@w.T@p2.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM1 = 12\n",
    "DIM2 = 4\n",
    "W = torch.rand(DIM1, DIM2)\n",
    "P1 = torch.rand(int(DIM1/2), DIM1)\n",
    "P2 = torch.rand(DIM2, int(DIM2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4])\n",
      "torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5.6443, 5.0776],\n",
       "        [6.5575, 5.7987],\n",
       "        [7.7880, 7.0714],\n",
       "        [7.1346, 6.4522],\n",
       "        [6.2099, 5.7591],\n",
       "        [7.6796, 6.9450]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = P1@W@P2\n",
    "print(W.shape)\n",
    "print(r.shape)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM1 = 50257\n",
    "DIM2 = 512\n",
    "W = torch.rand(DIM1, DIM2)\n",
    "P2 = torch.rand(DIM2, int(DIM2/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([502, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W@P2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6864, 0.3059],\n",
       "        [0.6783, 0.0089],\n",
       "        [0.8684, 0.8320],\n",
       "        [0.6172, 0.5390],\n",
       "        [0.8979, 0.8956]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb = 512\n",
    "# yb = 2048\n",
    "# xs = 256\n",
    "# ys = 1024\n",
    "# W = torch.rand(xb, yb)\n",
    "# P1 = torch.rand(xs, xb)\n",
    "# P2 = torch.rand(yb, ys)\n",
    "\n",
    "# r = P1@W@P2\n",
    "# print(W.shape)\n",
    "# print(r.shape)\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=8, bias=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lizrd.core.misc import Linear\n",
    "\n",
    "\n",
    "l = Linear(\n",
    "    4, #xs\n",
    "    8, #xb\n",
    "    init_type = \"kaiming_uniform\",\n",
    "    init_scale = 1.0\n",
    ")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (902681333.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Attention\":\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "# from lizrd.train.train_utils import get_model\n",
    "# from research.conditional.utils.model_utils import get_ff_layer\n",
    "# from research.projected_distillation.llm import ProjectedFeedForward\n",
    "# dmodel = 256\n",
    "# dff = 1024\n",
    "# projected_dmodel = dmodel*2\n",
    "# projected_dff = dff*2\n",
    "# n_blocks = 8\n",
    "# init_type = \"kaiming_uniform\"\n",
    "# init_scale= 1.0\n",
    "# block_modules = {\n",
    "#     \"FF\": lambda: ProjectedFeedForward(\n",
    "#             dmodel, dff, projected_dmodel, projected_dff, init_type=init_type, init_scale= init_scale\n",
    "#         ),\n",
    "#     \"Attention\": \n",
    "# }\n",
    "\n",
    "# model = get_model(\n",
    "#         max_length=256,\n",
    "#         vocab_size=50048,\n",
    "#         block_modules=block_modules,\n",
    "#         dm=dmodel,\n",
    "#         n_blocks=n_blocks,\n",
    "#         device=(\n",
    "#             torch.device(\"cuda\")\n",
    "#         ),  # in case of  DDP/FSDP, we initialize the model on CPU and move it to the GPU later\n",
    "#         init_type=init_type,\n",
    "#         init_scale=init_scale,\n",
    "#         ddp_enabled=False,\n",
    "#         fsdp_enabled=False,\n",
    "#         fsdp_param_precision=False,\n",
    "#         fsdp_mixed_precision_ignore_classes=False,\n",
    "#         fsdp_offload_params=False,\n",
    "#         fsdp_min_num_params=False,\n",
    "#         fsdp_modules_to_wrap=False,\n",
    "#         activation_checkpointing_modules=False,\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "randomllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
