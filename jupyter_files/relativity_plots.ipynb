{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune as neptune\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.ticker as mticker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neptune_table(tags, negative_tags=None):\n",
    "    project = neptune.init_project(\n",
    "        project=\"pmtest/llm-random\",\n",
    "        mode=\"read-only\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\"\n",
    "    )\n",
    "    runs_table = project.fetch_runs_table(tag=tags).to_pandas()\n",
    "    runs_table['sys/tags'] = runs_table['sys/tags'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "\n",
    "    # If negative tags are provided, filter them out\n",
    "    if negative_tags is not None:\n",
    "        for neg_tag in negative_tags:\n",
    "            runs_table = runs_table[~runs_table['sys/tags'].apply(lambda x: neg_tag in x)]\n",
    "\n",
    "    print(f'table downloaded\\nshape: {runs_table.shape}')\n",
    "    return runs_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neptune_table_by_ids(run_ids):\n",
    "    project = neptune.init_project(\n",
    "        project=\"pmtest/llm-random\",\n",
    "        mode=\"read-only\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\"\n",
    "    )\n",
    "    \n",
    "    runs_table = project.fetch_runs_table(id=run_ids).to_pandas()\n",
    "    \n",
    "    print(f'table downloaded by IDs\\nshape: {runs_table.shape}')\n",
    "    return runs_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_per_step(runs_table):\n",
    "    loss_dict = {}\n",
    "    for _, run_row in runs_table.iterrows():\n",
    "        run_id = run_row['sys/id']  # Assuming 'sys/id' is the run identifier\n",
    "        print(f'run ID: {run_id}')\n",
    "        project_name = \"pmtest/llm-random\"\n",
    "        # run_id = \"LLMRANDOM-2078\"\n",
    "        run = neptune.init_run(\n",
    "            project=project_name,\n",
    "            with_id=run_id,\n",
    "            mode=\"read-only\",\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\",\n",
    "        )\n",
    "        loss_dict[run_id] = run[f\"loss_interval/1\"].fetch_values()\n",
    "    return loss_dict\n",
    "\n",
    "def df_per_step(df, per_step):\n",
    "    # Calculate the rolling average of 'value' column with window size `per_step`\n",
    "    df['value'] = df['value'].rolling(window=per_step, min_periods=1).mean()\n",
    "    \n",
    "    # Select every `per_step`-th row from the end backwards, excluding the first step\n",
    "    selected_indices = list(range(len(df) - 1, 0, -per_step))  # Start from second last to skip the first step\n",
    "    selected_rows = df.iloc[selected_indices]\n",
    "    \n",
    "    # Sort the selected rows to maintain ascending step order\n",
    "    selected_rows = selected_rows.sort_index()\n",
    "    \n",
    "    return selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speedup(a, b, equation):\n",
    "    if equation == '(b-a)/b':\n",
    "        speedup = (b - a) / b\n",
    "    elif equation == '(b-a)/a':\n",
    "        speedup = (b - a) / a\n",
    "    elif equation == 'b/a':\n",
    "        speedup = b / a\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std(runs_spec_type, runs_1, runs_2, title, name_1, name_2, show_plot=False, save_to=None, figsize=(10, 10), ylim=None, x_start=None, loss_per=200):\n",
    "    b_v_r_negative_tags = ['remove']\n",
    "    if runs_spec_type == 'tags':\n",
    "        table_1 = get_neptune_table(runs_1, b_v_r_negative_tags)\n",
    "        table_2 = get_neptune_table(runs_2, b_v_r_negative_tags)\n",
    "    elif runs_spec_type == 'ids':\n",
    "        table_1 = get_neptune_table_by_ids(runs_1)\n",
    "        table_2 = get_neptune_table_by_ids(runs_2)\n",
    "    loss_dict_1 = get_loss_per_step(table_1)\n",
    "    loss_dict_2 = get_loss_per_step(table_2)\n",
    "\n",
    "    cutoff = table_1['args/cutoff'].iloc[0]\n",
    "    batch_size = table_1['args/batch_size'].iloc[0]\n",
    "    tokens_per_step = batch_size * cutoff\n",
    "\n",
    "    only_2_runs = False\n",
    "    if table_1.shape[0] + table_2.shape[0] == 2:\n",
    "        only_2_runs = True\n",
    "\n",
    "    # Concatenate the dataframes into one\n",
    "    df_1 = pd.concat([df.set_index('step')['value'] for df in loss_dict_1.values()], axis=1)\n",
    "    df_1 = df_per_step(df_1, loss_per)\n",
    "    df_2 = pd.concat([df.set_index('step')['value'] for df in loss_dict_2.values()], axis=1)\n",
    "    df_2 = df_per_step(df_2, loss_per)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    df_1['mean'] = df_1.mean(axis=1)\n",
    "    df_1['std'] = df_1.std(axis=1)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    df_2['mean'] = df_2.mean(axis=1)\n",
    "    df_2['std'] = df_2.std(axis=1)\n",
    "\n",
    "    df_1['tokens'] = df_1.index * tokens_per_step\n",
    "    df_2['tokens'] = df_2.index * tokens_per_step\n",
    "\n",
    "    # Reset the index to have 'step' as a column again\n",
    "    df_1 = df_1[['tokens', 'mean', 'std']].reset_index()\n",
    "    df_2 = df_2[['tokens', 'mean', 'std']].reset_index()\n",
    "\n",
    "    if show_plot:\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        # baseline\n",
    "        steps = df_1['tokens'].values\n",
    "        mean_values = df_1['mean'].values\n",
    "        std_values = df_1['std'].values\n",
    "\n",
    "        if x_start is not None:\n",
    "            first_index = np.argmax(steps > x_start)\n",
    "            steps = steps[first_index:]\n",
    "            mean_values = mean_values[first_index:]\n",
    "            std_values = std_values[first_index:]\n",
    "\n",
    "        if only_2_runs:\n",
    "            plt.plot(steps, mean_values, label=f'{name_1}', color='blue')\n",
    "        else:\n",
    "            plt.plot(steps, mean_values, label=f'{name_1} - mean', color='blue')\n",
    "            plt.fill_between(steps, mean_values - std_values, mean_values + std_values, \n",
    "                            color='blue', alpha=0.2, label=f'{name_1} - standard deviation')\n",
    "\n",
    "        #relative\n",
    "        steps = df_2['tokens'].values\n",
    "        mean_values = df_2['mean'].values\n",
    "        std_values = df_2['std'].values\n",
    "\n",
    "        if x_start is not None:\n",
    "            steps = steps[first_index:]\n",
    "            mean_values = mean_values[first_index:]\n",
    "            std_values = std_values[first_index:]\n",
    "        \n",
    "        if only_2_runs:\n",
    "            plt.plot(steps, mean_values, label=f'{name_2}', color='red')\n",
    "        else:\n",
    "            plt.plot(steps, mean_values, label=f'{name_2} - mean', color='red')\n",
    "            plt.fill_between(steps, mean_values - std_values, mean_values + std_values, \n",
    "                            color='red', alpha=0.2, label=f'{name_2} - standard deviation')\n",
    "\n",
    "        # # Plot individual dataframes from the dictionary\n",
    "        # for run_id, df in relative_loss_dict.items():\n",
    "        #     plt.plot(df['step'].values, df['value'].values, label=f'Run {run_id}')\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.gca().xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x*1e-9:.0f}B'))\n",
    "\n",
    "        plt.xlabel('Tokens', fontsize=24)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        \n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        plt.title(title, fontsize=26)  # Set title font size x2\n",
    "        # Show legend\n",
    "        plt.legend(fontsize=20)\n",
    "        if save_to is not None:\n",
    "            plt.savefig(save_to)\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "    # For baseline_df: Find the step with the lowest loss\n",
    "    min_loss_index_baseline = df_1['mean'].idxmin()\n",
    "    loss_baseline = df_1['mean'].values[min_loss_index_baseline]\n",
    "    std_baseline = df_1['std'].values[min_loss_index_baseline]\n",
    "    min_step_baseline = df_1['step'].values[min_loss_index_baseline]\n",
    "\n",
    "    # For relative_df: Find the first step where the mean loss is smaller than the baseline's minimum loss\n",
    "    smaller_loss_condition = df_2['mean'] <= loss_baseline\n",
    "\n",
    "    if smaller_loss_condition.any():  # Check if there's any step with a smaller mean loss\n",
    "        first_smaller_step_relative = df_2[smaller_loss_condition]['step'].values[0]\n",
    "        loss_relative = df_2[smaller_loss_condition]['mean'].values[0]\n",
    "        std_relative = df_2[smaller_loss_condition]['std'].values[0]\n",
    "        \n",
    "        # Calculate speedup using the found steps\n",
    "        speedup = calculate_speedup(a=first_smaller_step_relative, b=min_step_baseline, equation='b/a')\n",
    "    else:\n",
    "        # No step has a smaller mean loss\n",
    "        first_smaller_step_relative = None\n",
    "        loss_relative = None\n",
    "        std_relative = None\n",
    "        speedup = None\n",
    "\n",
    "    return (min_step_baseline, loss_baseline, std_baseline), (first_smaller_step_relative, loss_relative, std_relative), speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_dict_append(component_name, baseline, relative, speedup_relative, speedup_baseline, results_dict=None):\n",
    "    # Unpack the tuples for easier readability\n",
    "    (last_step_baseline, loss_baseline, std_baseline), (first_smaller_step_relative, loss_relative, std_relative) = baseline, relative\n",
    "    \n",
    "    # Check if results_dict is None and initialize if necessary\n",
    "    if results_dict is None:\n",
    "        results_dict = {\n",
    "            'component': [],\n",
    "            'total_tokens': [],\n",
    "            'faster_tokens': [],\n",
    "            'speedup_relative': [],\n",
    "            'speedup_baseline': [],\n",
    "        }\n",
    "\n",
    "    # Calculate values to be added to the table\n",
    "    total_tokens = last_step_baseline\n",
    "    faster_tokens = first_smaller_step_relative if first_smaller_step_relative is not None else \"N/A\"\n",
    "    speedup_relative = speedup_relative if speedup_relative is not None else \"N/A\"\n",
    "    speedup_baseline = speedup_baseline if speedup_baseline is not None else \"N/A\"\n",
    "    \n",
    "    # Append results to the dictionary\n",
    "    results_dict['component'].append(component_name)\n",
    "    results_dict['total_tokens'].append(total_tokens)\n",
    "    results_dict['faster_tokens'].append(faster_tokens)\n",
    "    results_dict['speedup_relative'].append(speedup_relative)\n",
    "    results_dict['speedup_baseline'].append(speedup_baseline)\n",
    "    \n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std_component(table, component_name, start_end, ax=None):\n",
    "    print(f'component_name: {component_name}, start_end: {start_end}')\n",
    "    se_convert = {\n",
    "        'start': 'relative_lr',\n",
    "        'end': 'relative_scheduler_fraction'\n",
    "    }\n",
    "    dict_name = se_convert[start_end]\n",
    "    args_column = f'args/{dict_name}/{component_name}'\n",
    "\n",
    "    filtered_table = table[table['sys/tags'].apply(lambda tags: component_name in tags and start_end in tags)]\n",
    "    optimal_table = table[table['sys/tags'].apply(lambda tags: 'relative' in tags)]\n",
    "    \n",
    "    columns = ['loss', args_column]\n",
    "    filtered_table = filtered_table[columns]\n",
    "\n",
    "    x_1_table = filtered_table[filtered_table[args_column] == 1]\n",
    "    filtered_table = filtered_table[filtered_table[args_column] != 1]\n",
    "\n",
    "    grouped_data = filtered_table.groupby(args_column)['loss'].agg(['mean', 'min', 'max']).reset_index()\n",
    "    x_1_data = x_1_table.groupby(args_column)['loss'].agg(['mean', 'min', 'max']).reset_index()\n",
    "    optimal_grouped = optimal_table.groupby(args_column)['loss'].agg(['mean', 'min', 'max']).reset_index()\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Keep original x-values\n",
    "    x_values = grouped_data[args_column].values\n",
    "    x_1_values = x_1_data[args_column].values\n",
    "    x_optimal = optimal_grouped[args_column].values\n",
    "\n",
    "    # Print rounded values for debugging (optional)\n",
    "    print(f'Rounded x_values: {np.round(x_values, 2)}')\n",
    "    print(f'Rounded x_1_values: {np.round(x_1_values, 2)}')\n",
    "    print(f'Rounded x_optimal: {np.round(x_optimal, 2)}')\n",
    "\n",
    "    yerr = np.vstack([grouped_data['mean'] - grouped_data['min'], grouped_data['max'] - grouped_data['mean']])\n",
    "    x_1_yerr = np.vstack([x_1_data['mean'] - x_1_data['min'], x_1_data['max'] - x_1_data['mean']])\n",
    "    optimal_yerr = np.vstack([optimal_grouped['mean'] - optimal_grouped['min'], optimal_grouped['max'] - optimal_grouped['mean']])\n",
    "\n",
    "    # Plot other relative and optimal relative\n",
    "    line1 = ax.errorbar(x=x_values, y=grouped_data['mean'], yerr=yerr, fmt='o', color='blue', capsize=5, label='Other relative')\n",
    "    line2 = ax.errorbar(x=x_optimal, y=optimal_grouped['mean'], yerr=optimal_yerr, fmt='o', color='green', label='RLRS', capsize=5)\n",
    "\n",
    "    # Plot baseline (no relative) with LaTeX for lambda\n",
    "    line3 = ax.errorbar(x=x_1_values, y=x_1_data['mean'], yerr=x_1_yerr, fmt='o', color='red', label=r'$\\lambda = 1$', capsize=5)\n",
    "\n",
    "    # Set the x-axis to a log scale\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    # Customize x-axis tick labels to display as regular numbers\n",
    "    ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "    # Set x-ticks and gridlines for other relative and optimal relative data\n",
    "    x_values_combined = np.concatenate((x_values, x_optimal))  # Combine relevant x-values\n",
    "    x_values_combined = np.unique(x_values_combined)  # Ensure unique values\n",
    "\n",
    "    # Remove second-first and second-last x-ticks\n",
    "    if len(x_values_combined) > 4:  # Make sure we have enough ticks\n",
    "        x_values_combined = np.delete(x_values_combined, [1, -2])\n",
    "\n",
    "    # Set ticks and manually set rounded labels\n",
    "    ax.set_xticks(x_values_combined)\n",
    "    ax.set_xticklabels(np.round(x_values_combined, 2))\n",
    "\n",
    "    ax.grid(True, which='major', linestyle='--', linewidth=0.5)  # Keep the grid for relevant data\n",
    "\n",
    "    # Return the line objects for the shared legend\n",
    "    return line1, line2, line3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_plot(\n",
    "    model_name, \n",
    "    u_plot_table,\n",
    "    component_names, \n",
    "    start_ends,\n",
    "    figsize=(25, 10),\n",
    "    ylim=(3, 4),\n",
    "    title_fontsize=20, \n",
    "    xlabel_fontsize=18, \n",
    "    ylabel_fontsize=18, \n",
    "    tick_fontsize=14,\n",
    "    legend_fontsize=16,\n",
    "    row_spacing=1.0,\n",
    "    legend_spacing=0.05  # Add parameter to control space between legend and plot\n",
    "):\n",
    "    # Simplified titles for each column\n",
    "    names_converter = {\n",
    "        'embedding_layer': 'Embedding',\n",
    "        'head': 'Unembedding',\n",
    "        'gating': 'Router',\n",
    "        'expert_inner_function': 'Expert',\n",
    "        'projection': 'Attention',\n",
    "    }\n",
    "\n",
    "    print(f'There are {u_plot_table.shape[0]} runs')\n",
    "\n",
    "    # Create subplots with 2 rows and 5 columns\n",
    "    fig, axs = plt.subplots(len(start_ends), len(component_names), sharey=True, figsize=figsize)\n",
    "\n",
    "    # List to collect the lines for the shared legend\n",
    "    all_lines = []\n",
    "\n",
    "    # Loop through components and start_ends\n",
    "    for i, start_end in enumerate(start_ends):\n",
    "        for j, name in enumerate(component_names):\n",
    "            ax = axs[i, j]\n",
    "            line1, line2, line3 = plot_std_component(table=u_plot_table, component_name=name, start_end=start_end, ax=ax)\n",
    "            all_lines = [line1, line2, line3]\n",
    "            \n",
    "            # Only add the title for the top subplot (first row) in each column\n",
    "            if i == 0:\n",
    "                ax.set_title(f'{names_converter[name]}', fontsize=title_fontsize)\n",
    "            \n",
    "            # Only add y-axis labels for the first column in each row\n",
    "            if j == 0:\n",
    "                ax.set_ylabel('Loss', fontsize=ylabel_fontsize)\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")  # Remove the y-axis label for other subplots in the row\n",
    "\n",
    "            # Set x-axis labels with correct LaTeX formatting using \\mathit\n",
    "            if i == 0:\n",
    "                ax.set_xlabel(r'$\\lambda_{\\mathit{start}}^{\\mathit{' + f'{names_converter[name]}' + '}}$', fontsize=xlabel_fontsize)\n",
    "            else:\n",
    "                ax.set_xlabel(r'$\\lambda_{\\mathit{end}}^{\\mathit{' + f'{names_converter[name]}' + '}}$', fontsize=xlabel_fontsize)\n",
    "            \n",
    "            # Rotate x-axis labels and set tick font sizes\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_rotation(45)\n",
    "            ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "            ax.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "\n",
    "    # Adjust y-limits for all subplots\n",
    "    for ax in axs.flat:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    # Add shared legend with controlled spacing\n",
    "    fig.legend(handles=[line1, line2, line3], labels=['Varying ' + r'$\\lambda$', 'RLRS', r'$\\lambda = 1$'],\n",
    "               loc='upper center', fontsize=legend_fontsize, ncol=3, bbox_to_anchor=(0.5, 1 + legend_spacing), bbox_transform=fig.transFigure)\n",
    "\n",
    "    # Adjust layout to make room for labels\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=row_spacing, top=0.85 - legend_spacing)  # Adjust row spacing and top margin here\n",
    "    plt.savefig(f'U-plots-{model_name}.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_plot_component(\n",
    "    model_name, \n",
    "    u_plot_table, \n",
    "    component_name,  # Single component argument\n",
    "    start_ends,\n",
    "    figsize=(12, 5),  # Adjusted figure size for a single row\n",
    "    ylim=(3, 4),\n",
    "    title_fontsize=20, \n",
    "    xlabel_fontsize=18, \n",
    "    ylabel_fontsize=18, \n",
    "    tick_fontsize=14,\n",
    "    legend_fontsize=16,\n",
    "    row_spacing=1.0,\n",
    "    legend_spacing=0.05  # Control space between legend and plot\n",
    "):\n",
    "    # Simplified title for the single component\n",
    "    names_converter = {\n",
    "        'embedding_layer': 'Embedding',\n",
    "        'head': 'Unembedding',\n",
    "        'gating': 'Router',\n",
    "        'expert_inner_function': 'Expert',\n",
    "        'projection': 'Attention',\n",
    "    }\n",
    "\n",
    "    print(f'There are {u_plot_table.shape[0]} runs')\n",
    "\n",
    "    # Create subplots with 1 row and len(start_ends) columns\n",
    "    fig, axs = plt.subplots(1, len(start_ends), sharey=True, figsize=figsize)\n",
    "\n",
    "    # List to collect the lines for the shared legend\n",
    "    all_lines = []\n",
    "\n",
    "    # Loop through start_ends (only one component in a row)\n",
    "    for i, start_end in enumerate(start_ends):\n",
    "        ax = axs[i]\n",
    "        line1, line2, line3 = plot_std_component(table=u_plot_table, component_name=component_name, start_end=start_end, ax=ax)\n",
    "        \n",
    "        # Add y-axis label for the first subplot in the row\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Loss', fontsize=ylabel_fontsize)\n",
    "\n",
    "        # Set title for each plot based on start_end\n",
    "        ax.set_title(f'{names_converter[component_name]} ({start_end})', fontsize=title_fontsize)\n",
    "\n",
    "        # Set x-axis labels with correct LaTeX formatting using \\mathit\n",
    "        if start_end == 'start':\n",
    "            ax.set_xlabel(r'$\\lambda_{\\mathit{start}}^{\\mathit{' + f'{names_converter[component_name]}' + '}}$', fontsize=xlabel_fontsize)\n",
    "        else:\n",
    "            ax.set_xlabel(r'$\\lambda_{\\mathit{end}}^{\\mathit{' + f'{names_converter[component_name]}' + '}}$', fontsize=xlabel_fontsize)\n",
    "        \n",
    "        # Rotate x-axis labels and set tick font sizes\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_rotation(45)\n",
    "        ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "        ax.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "\n",
    "    # Adjust y-limits for all subplots\n",
    "    for ax in axs.flat:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    # Add shared legend with controlled spacing\n",
    "    fig.legend(handles=[line1, line2, line3], labels=['Varying ' + r'$\\lambda$', 'RLRS'],\n",
    "               loc='upper center', fontsize=legend_fontsize, ncol=3, bbox_to_anchor=(0.5, 1 + legend_spacing), bbox_transform=fig.transFigure)\n",
    "\n",
    "    # Adjust layout to make room for labels\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=row_spacing, top=0.85 - legend_spacing)  # Adjust row spacing and top margin here\n",
    "    plt.savefig(f'U-plot-{names_converter[component_name]}.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium (30M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "CannotResolveHostname",
     "evalue": "\n\u001b[95m\n----CannotResolveHostname-----------------------------------------------------------------------\n\u001b[0m\nThe Neptune client library was not able to resolve hostname \u001b[4mapp.neptune.ai\u001b[0m.\n\nWhat should I do?\n    - Check if your computer is connected to the internet.\n    - Check if your computer is supposed to be using a proxy to access the internet.\n      If so, you may want to use the \u001b[96mproxies\u001b[0m parameter of the \u001b[96minit_run()\u001b[0m function.\n      See https://docs.neptune.ai/api/universal/#proxies\n      and https://requests.readthedocs.io/en/latest/user/advanced/#proxies\n    - Check the status of Neptune services: https://status.neptune.ai/\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting_help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/utils.py:93\u001b[0m, in \u001b[0;36mverify_host_resolution\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgethostbyname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror:\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCannotResolveHostname\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m b_v_r_tags_baseline \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelativity_paper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m b_v_r_tags_relative \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelativity_paper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m (all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup \u001b[38;5;241m=\u001b[39m \u001b[43mplot_std\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruns_spec_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruns_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_v_r_tags_baseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruns_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_v_r_tags_relative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMedium (33M)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBaseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRelative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedium_relative_vs_baseline.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_per\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeedup: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeedup\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m tokens_per_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m512\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mplot_std\u001b[0;34m(runs_spec_type, runs_1, runs_2, title, name_1, name_2, show_plot, save_to, figsize, ylim, x_start, loss_per)\u001b[0m\n\u001b[1;32m      2\u001b[0m b_v_r_negative_tags \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremove\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m runs_spec_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     table_1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_neptune_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_v_r_negative_tags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     table_2 \u001b[38;5;241m=\u001b[39m get_neptune_table(runs_2, b_v_r_negative_tags)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m runs_spec_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m, in \u001b[0;36mget_neptune_table\u001b[0;34m(tags, negative_tags)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_neptune_table\u001b[39m(tags, negative_tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[43mneptune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_project\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpmtest/llm-random\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mread-only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     runs_table \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mfetch_runs_table(tag\u001b[38;5;241m=\u001b[39mtags)\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m      8\u001b[0m     runs_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msys/tags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m runs_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msys/tags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/metadata_containers/project.py:160\u001b[0m, in \u001b[0;36mProject.__init__\u001b[0;34m(self, project, api_token, mode, flush_period, proxies, async_lag_callback, async_lag_threshold, async_no_progress_callback, async_no_progress_threshold)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m Mode\u001b[38;5;241m.\u001b[39mOFFLINE:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NeptuneException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be initialized in OFFLINE mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflush_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_lag_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_lag_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_lag_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_lag_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_no_progress_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_no_progress_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_no_progress_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_no_progress_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/metadata_containers/metadata_container.py:144\u001b[0m, in \u001b[0;36mMetadataContainer.__init__\u001b[0;34m(self, project, api_token, mode, flush_period, proxies, async_lag_callback, async_lag_threshold, async_no_progress_callback, async_no_progress_threshold)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forking_state: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state: ContainerState \u001b[38;5;241m=\u001b[39m ContainerState\u001b[38;5;241m.\u001b[39mCREATED\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend: NeptuneBackend \u001b[38;5;241m=\u001b[39m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_qualified_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m conform_optional(project, QualifiedName)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_api_object: Project \u001b[38;5;241m=\u001b[39m project_name_lookup(\n\u001b[1;32m    148\u001b[0m     backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_qualified_name\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/factory.py:39\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(mode, api_token, proxies)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OfflineNeptuneBackend()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m Mode\u001b[38;5;241m.\u001b[39mREAD_ONLY:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHostedNeptuneBackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_token\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mm\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mMode]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/hosted_neptune_backend.py:159\u001b[0m, in \u001b[0;36mHostedNeptuneBackend.__init__\u001b[0;34m(self, credentials, proxies)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxies \u001b[38;5;241m=\u001b[39m proxies\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_http_client_with_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_verify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_verify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: (RequestsClient, ClientConfig)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_client \u001b[38;5;241m=\u001b[39m create_backend_client(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaderboard_client \u001b[38;5;241m=\u001b[39m create_leaderboard_client(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client)\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/utils.py:228\u001b[0m, in \u001b[0;36mcache.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([HDict(arg) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[1;32m    227\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: HDict(v) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/hosted_client.py:140\u001b[0m, in \u001b[0;36mcreate_http_client_with_auth\u001b[0;34m(credentials, ssl_verify, proxies)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;129m@cache\u001b[39m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_http_client_with_auth\u001b[39m(\n\u001b[1;32m    138\u001b[0m     credentials: Credentials, ssl_verify: \u001b[38;5;28mbool\u001b[39m, proxies: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[RequestsClient, ClientConfig]:\n\u001b[0;32m--> 140\u001b[0m     client_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_client_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_verify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_verify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     config_api_url \u001b[38;5;241m=\u001b[39m credentials\u001b[38;5;241m.\u001b[39mapi_url_opt \u001b[38;5;129;01mor\u001b[39;00m credentials\u001b[38;5;241m.\u001b[39mtoken_origin_address\n\u001b[1;32m    144\u001b[0m     verify_client_version(client_config, neptune_client_version)\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/utils.py:228\u001b[0m, in \u001b[0;36mcache.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([HDict(arg) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[1;32m    227\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: HDict(v) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/common/backends/utils.py:75\u001b[0m, in \u001b[0;36mwith_api_exceptions_handler.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidHeader \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Neptune-Api-Token\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/hosted_client.py:118\u001b[0m, in \u001b[0;36mget_client_config\u001b[0;34m(credentials, ssl_verify, proxies)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@cache\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;129m@with_api_exceptions_handler\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_client_config\u001b[39m(credentials: Credentials, ssl_verify: \u001b[38;5;28mbool\u001b[39m, proxies: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClientConfig:\n\u001b[0;32m--> 118\u001b[0m     backend_client \u001b[38;5;241m=\u001b[39m \u001b[43m_get_token_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_verify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_verify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    121\u001b[0m         backend_client\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mgetClientConfig(\n\u001b[1;32m    122\u001b[0m             X_Neptune_Api_Token\u001b[38;5;241m=\u001b[39mcredentials\u001b[38;5;241m.\u001b[39mapi_token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;241m.\u001b[39mresult\n\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    130\u001b[0m     client_config \u001b[38;5;241m=\u001b[39m ClientConfig\u001b[38;5;241m.\u001b[39mfrom_api_response(config)\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/utils.py:228\u001b[0m, in \u001b[0;36mcache.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([HDict(arg) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[1;32m    227\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: HDict(v) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/hosted_client.py:103\u001b[0m, in \u001b[0;36m_get_token_client\u001b[0;34m(credentials, ssl_verify, proxies, endpoint_url)\u001b[0m\n\u001b[1;32m    101\u001b[0m config_api_url \u001b[38;5;241m=\u001b[39m credentials\u001b[38;5;241m.\u001b[39mapi_url_opt \u001b[38;5;129;01mor\u001b[39;00m credentials\u001b[38;5;241m.\u001b[39mtoken_origin_address\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[43mverify_host_resolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_api_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m token_http_client \u001b[38;5;241m=\u001b[39m create_http_client(ssl_verify, proxies)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SwaggerClientWrapper(\n\u001b[1;32m    108\u001b[0m     create_swagger_client(\n\u001b[1;32m    109\u001b[0m         build_operation_url(endpoint_url \u001b[38;5;129;01mor\u001b[39;00m config_api_url, BACKEND_SWAGGER_PATH),\n\u001b[1;32m    110\u001b[0m         token_http_client,\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/IDEAS/llm-random/venv/lib/python3.10/site-packages/neptune/internal/backends/utils.py:95\u001b[0m, in \u001b[0;36mverify_host_resolution\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     93\u001b[0m     socket\u001b[38;5;241m.\u001b[39mgethostbyname(host)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotResolveHostname(host)\n",
      "\u001b[0;31mCannotResolveHostname\u001b[0m: \n\u001b[95m\n----CannotResolveHostname-----------------------------------------------------------------------\n\u001b[0m\nThe Neptune client library was not able to resolve hostname \u001b[4mapp.neptune.ai\u001b[0m.\n\nWhat should I do?\n    - Check if your computer is connected to the internet.\n    - Check if your computer is supposed to be using a proxy to access the internet.\n      If so, you may want to use the \u001b[96mproxies\u001b[0m parameter of the \u001b[96minit_run()\u001b[0m function.\n      See https://docs.neptune.ai/api/universal/#proxies\n      and https://requests.readthedocs.io/en/latest/user/advanced/#proxies\n    - Check the status of Neptune services: https://status.neptune.ai/\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting_help\n"
     ]
    }
   ],
   "source": [
    "b_v_r_tags_baseline = ['relativity_paper', 'medium_model', 'std', 'baseline']\n",
    "b_v_r_tags_relative = ['relativity_paper', 'medium_model', 'std', 'relative']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='tags',\n",
    "    runs_1=b_v_r_tags_baseline,\n",
    "    runs_2=b_v_r_tags_relative,\n",
    "    title='Medium (33M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='medium_relative_vs_baseline.png',\n",
    "    ylim=(3.4, 4),\n",
    "    x_start=0,\n",
    "    loss_per=100,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 128 * 512\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000, 0)}M, relative tokens: {round(relative_steps * tokens_per_step / 1000000, 0)}M')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base (100M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_r_tags_baseline = ['relativity_paper', 'base_model', 'std', 'baseline']\n",
    "b_v_r_tags_relative = ['relativity_paper', 'base_model', 'std', 'relative']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='tags',\n",
    "    runs_1=b_v_r_tags_baseline,\n",
    "    runs_2=b_v_r_tags_relative,\n",
    "    title='Base (100M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='base_relative_vs_baseline.png',\n",
    "    ylim=(3.2, 3.7),\n",
    "    x_start=0,\n",
    "    loss_per=200,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 256 * 512\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000000, 2)}B, relative tokens: {round(relative_steps * tokens_per_step / 1000000000, 2)}B')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large (1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_r_tags_baseline = ['relativity_paper', 'large_model', 'std', 'baseline']\n",
    "b_v_r_tags_relative = ['relativity_paper', 'large_model', 'std', 'relative']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='tags',\n",
    "    runs_1=b_v_r_tags_baseline,\n",
    "    runs_2=b_v_r_tags_relative,\n",
    "    title='Large (906M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='base_relative_vs_baseline.png',\n",
    "    ylim=(2.6, 3.2),\n",
    "    x_start=0,\n",
    "    loss_per=500,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 384 * 1024\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000000, 2)}B, relative tokens: {round(relative_steps * tokens_per_step / 1000000000, 2)}B')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base (100M) Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_r_tags_baseline = ['relativity_paper', 'base_model', 'long', 'baseline']\n",
    "b_v_r_tags_relative = ['relativity_paper', 'base_model', 'long', 'relative']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='tags',\n",
    "    runs_1=b_v_r_tags_baseline,\n",
    "    runs_2=b_v_r_tags_relative,\n",
    "    title='Base (100M) - long training',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='base_long_relative_vs_baseline.png',\n",
    "    ylim=(2.9, 3.7),\n",
    "    x_start=0,\n",
    "    loss_per=1000,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 256 * 512\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000000, 2)}B, relative tokens: {round(relative_steps * tokens_per_step / 1000000000, 2)}B')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_r_tags_baseline = ['relativity_paper', 'dense', 'medium_model', 'baseline']\n",
    "b_v_r_tags_relative = ['relativity_paper', 'dense', 'medium_model', 'relative']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='tags',\n",
    "    runs_1=b_v_r_tags_baseline,\n",
    "    runs_2=b_v_r_tags_relative,\n",
    "    title='Medium Dense (33M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='medium_dense_relative_vs_baseline.png',\n",
    "    ylim=(3.5, 4),\n",
    "    x_start=0,\n",
    "    loss_per=100,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 256 * 512\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000, 0)}M, relative tokens: {round(relative_steps * tokens_per_step / 1000000, 0)}M')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_r_tags_baseline = ['relativity_paper', 'dense', 'base_model', 'baseline']\n",
    "b_v_r_tags_relative = ['relativity_paper', 'dense', 'base_model', 'relative']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='tags',\n",
    "    runs_1=b_v_r_tags_baseline,\n",
    "    runs_2=b_v_r_tags_relative,\n",
    "    title='Base Dense (100M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='base_dense_relative_vs_baseline.png',\n",
    "    ylim=(3.3, 3.7),\n",
    "    x_start=0,\n",
    "    loss_per=200,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 256 * 512\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000, 0)}M, relative tokens: {round(relative_steps * tokens_per_step / 1000000, 0)}M')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large (1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_baseline= ['LLMRANDOM-13393']\n",
    "runs_relative= ['LLMRANDOM-13404']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='ids',\n",
    "    runs_1=runs_baseline,\n",
    "    runs_2=runs_relative,\n",
    "    title='Large Dense (906M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='large_dense_relative_vs_baseline.png',\n",
    "    ylim=(2.6, 4),\n",
    "    x_start=0,\n",
    "    loss_per=500,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 384 * 1024\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1e9, 0)}B, relative tokens: {round(relative_steps * tokens_per_step / 1e9, 0)}B')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium (30M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_plot_tags = ['relativity_paper', 'medium_model', 'uplot']\n",
    "u_plot_negative_tags = ['remove']\n",
    "\n",
    "table = get_neptune_table(tags=u_plot_tags, negative_tags=u_plot_negative_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_names = ['embedding_layer', 'head', 'gating', 'expert_inner_function', 'projection']\n",
    "start_ends = ['start', 'end']\n",
    "model_name = 'Medium (30M)'\n",
    "\n",
    "U_plot(\n",
    "    model_name=model_name,\n",
    "    u_plot_table=table,\n",
    "    component_names=component_names,\n",
    "    start_ends=start_ends,\n",
    "    ylim=(3.5, 3.675)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base (100M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_plot_tags = ['relativity_paper', 'base_model', 'uplot']\n",
    "u_plot_negative_tags = ['remove']\n",
    "\n",
    "table = get_neptune_table(tags=u_plot_tags, negative_tags=u_plot_negative_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# component_names = ['embedding_layer', 'head', 'gating', 'expert_inner_function', 'projection']\n",
    "component_names = ['embedding_layer', 'head', 'gating', 'expert_inner_function']\n",
    "start_ends = ['start', 'end']\n",
    "model_name = 'Base (100M)'\n",
    "\n",
    "U_plot(\n",
    "    model_name=model_name,\n",
    "    u_plot_table=table,\n",
    "    component_names=component_names,\n",
    "    start_ends=start_ends,\n",
    "    figsize=(16, 9.5),\n",
    "    ylim=(3.22, 3.35),\n",
    "    title_fontsize=23, \n",
    "    xlabel_fontsize=27, \n",
    "    ylabel_fontsize=23, \n",
    "    tick_fontsize=17,\n",
    "    legend_fontsize=20,\n",
    "    row_spacing=0.58,\n",
    "    legend_spacing=-0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ends = ['start', 'end']\n",
    "model_name = 'Base (100M)'\n",
    "\n",
    "U_plot_component(\n",
    "    model_name=model_name,\n",
    "    u_plot_table=table,\n",
    "    component_name='projection',\n",
    "    start_ends=start_ends,\n",
    "    figsize=(16, 9.5),\n",
    "    ylim=(3.24, 3.32),\n",
    "    title_fontsize=23, \n",
    "    xlabel_fontsize=27, \n",
    "    ylabel_fontsize=23, \n",
    "    tick_fontsize=17,\n",
    "    legend_fontsize=20,\n",
    "    row_spacing=0.58,\n",
    "    legend_spacing=-0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium (30M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'medium_model'\n",
    "\n",
    "component_names = ['embedding_layer', 'head', 'gating', 'expert_inner_function']\n",
    "tags_relative = ['relativity_paper', model_type, 'removal', 'relative']\n",
    "tags_baseline = ['relativity_paper', model_type, 'removal', 'baseline']\n",
    "results_dict = None\n",
    "\n",
    "for component in component_names:\n",
    "    print(f'component: {component}')\n",
    "    tags_component = ['relativity_paper', model_type, 'removal', component]\n",
    "\n",
    "    baseline, relative, speedup = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_component,\n",
    "        runs_2=tags_relative,\n",
    "        title='Medium (33M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    _, _, speedup_baseline = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_baseline,\n",
    "        runs_2=tags_component,\n",
    "        title='Medium (33M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    results_dict = results_dict_append(component, baseline, relative, speedup, speedup_baseline, results_dict)\n",
    "\n",
    "df = pd.DataFrame(results_dict)\n",
    "print(df)\n",
    "print()\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base (100M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'base_model'\n",
    "\n",
    "tags_component = ['embedding_layer', 'head', 'gating', 'expert_inner_function']\n",
    "tags_relative = ['relativity_paper', model_type, 'removal', 'relative']\n",
    "tags_baseline = ['relativity_paper', model_type, 'removal', 'baseline']\n",
    "results_dict = None\n",
    "\n",
    "for component in component_names:\n",
    "    print(f'component: {component}')\n",
    "    tags_component = ['relativity_paper', model_type, 'removal', component]\n",
    "\n",
    "    baseline, relative, speedup = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_component,\n",
    "        runs_2=tags_relative,\n",
    "        title='Vase (100M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    _, _, speedup_baseline = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_baseline,\n",
    "        runs_2=tags_component,\n",
    "        title='Base (100M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    results_dict = results_dict_append(component, baseline, relative, speedup, speedup_baseline, results_dict)\n",
    "    \n",
    "df = pd.DataFrame(results_dict)\n",
    "print(df)\n",
    "print()\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium (30M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'medium_model'\n",
    "\n",
    "tags_component = ['embedding_layer', 'head', 'gating', 'expert_inner_function']\n",
    "tags_relative = ['relativity_paper', model_type, 'contribution', 'relative']\n",
    "tags_baseline = ['relativity_paper', model_type, 'contribution', 'baseline']\n",
    "results_dict = None\n",
    "\n",
    "for component in component_names:\n",
    "    print(f'component: {component}')\n",
    "    tags_component = ['relativity_paper', model_type, 'removal', component]\n",
    "\n",
    "    baseline, relative, speedup = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_component,\n",
    "        runs_2=tags_relative,\n",
    "        title='Medium (33M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    _, _, speedup_baseline = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_baseline,\n",
    "        runs_2=tags_component,\n",
    "        title='Medium (33M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    results_dict = results_dict_append(component, baseline, relative, speedup, speedup_baseline, results_dict)\n",
    "\n",
    "df = pd.DataFrame(results_dict)\n",
    "print(df)\n",
    "print()\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base (100M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'base_model'\n",
    "\n",
    "tags_component = ['embedding_layer', 'head', 'gating', 'expert_inner_function']\n",
    "tags_relative = ['relativity_paper', model_type, 'contribution', 'relative']\n",
    "tags_baseline = ['relativity_paper', model_type, 'contribution', 'baseline']\n",
    "results_dict = None\n",
    "\n",
    "for component in component_names:\n",
    "    print(f'component: {component}')\n",
    "    tags_component = ['relativity_paper', model_type, 'removal', component]\n",
    "\n",
    "    baseline, relative, speedup = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_component,\n",
    "        runs_2=tags_relative,\n",
    "        title='Base (100M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    _, _, speedup_baseline = plot_std(\n",
    "        runs_spec_type='tags',\n",
    "        runs_1=tags_baseline,\n",
    "        runs_2=tags_component,\n",
    "        title='Base (100M)',\n",
    "        name_1='Baseline',\n",
    "        name_2='Relative',\n",
    "        show_plot=False,\n",
    "        save_to=None,\n",
    "        ylim=(3.5, 4),\n",
    "        x_start=0,\n",
    "    )\n",
    "\n",
    "    results_dict = results_dict_append(component, baseline, relative, speedup, speedup_baseline, results_dict)\n",
    "\n",
    "df = pd.DataFrame(results_dict)\n",
    "print(df)\n",
    "print()\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runs_baseline= ['LLMRANDOM-14973']\n",
    "runs_relative= ['LLMRANDOM-15082']\n",
    "\n",
    "(all_steps, baseline_loss, baseline_std), (relative_steps, relative_loss, relative_std), speedup = plot_std(\n",
    "    runs_spec_type='ids',\n",
    "    runs_1=runs_baseline,\n",
    "    runs_2=runs_relative,\n",
    "    title='Large MoE (906M)',\n",
    "    name_1='Baseline',\n",
    "    name_2='Relative',\n",
    "    show_plot=True,\n",
    "    save_to='large_relative_vs_baseline.pdf',\n",
    "    ylim=(2.6, 4.2),\n",
    "    x_start=0,\n",
    ")\n",
    "\n",
    "print(f'speedup: {speedup}')\n",
    "tokens_per_step = 384 * 1024\n",
    "print(f'total tokens: {round(all_steps * tokens_per_step / 1000000, 0)}M, relative tokens: {round(relative_steps * tokens_per_step / 1000000, 0)}M')\n",
    "print(f'std baseline: {baseline_std}, std relative: {relative_std}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
