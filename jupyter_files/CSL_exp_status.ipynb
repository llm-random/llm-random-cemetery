{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune as neptune\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neptune_table(tags, negative_tags=None, active=False):\n",
    "    project = neptune.init_project(\n",
    "        project=\"pmtest/llm-random\",\n",
    "        mode=\"read-only\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\"\n",
    "    )\n",
    "    if active:\n",
    "        runs_table = project.fetch_runs_table(tag=tags, state='active').to_pandas()\n",
    "    else:\n",
    "        runs_table = project.fetch_runs_table(tag=tags).to_pandas()\n",
    "\n",
    "    # If negative tags are provided, filter them out\n",
    "    if negative_tags is not None:\n",
    "        for neg_tag in negative_tags:\n",
    "            runs_table = runs_table[~runs_table['sys/tags'].apply(lambda x: neg_tag in x)]\n",
    "\n",
    "    print(f'table downloaded\\nshape: {runs_table.shape}')\n",
    "    return runs_table\n",
    "\n",
    "def get_training_progress_with_eta(runs_table, run_specs, active=False):\n",
    "    # Filter runs based on the provided specifications\n",
    "    for column, value in run_specs.items():\n",
    "        if value is not None:\n",
    "            runs_table = runs_table[runs_table[column] == value]\n",
    "\n",
    "    if runs_table.empty:\n",
    "        print(\"No runs found with the specified criteria.\")\n",
    "        return None\n",
    "    results = []\n",
    "    \n",
    "    for idx, run in runs_table.iterrows():        \n",
    "        # Fetch necessary information\n",
    "        exp_id = run['sys/id']\n",
    "        current_step = run[\"step\"]\n",
    "        n_steps = run[\"args/n_steps\"]\n",
    "        time_running = run['sys/running_time']\n",
    "        n_gpus = run['args/n_gpus']\n",
    "\n",
    "        # Calculate the percentage of training completed\n",
    "        if n_steps > 0:\n",
    "            percent_finished = (current_step / n_steps) * 100\n",
    "        else:\n",
    "            percent_finished = 0.0\n",
    "        \n",
    "        # Estimate ETA (remaining time)\n",
    "        if current_step > 0:\n",
    "            time_per_step = time_running / current_step\n",
    "            remaining_steps = n_steps - current_step\n",
    "            time_left = time_per_step * remaining_steps\n",
    "            # time_left_hours = time_left.total_seconds() / 3600  # Convert to hours\n",
    "        else:\n",
    "            time_left = None\n",
    "        \n",
    "        # Collect the data into a dictionary\n",
    "        result = {\n",
    "            # \"args/name\": run.get(\"args/name\", None),\n",
    "            \"ID\": exp_id,\n",
    "            \"time_running\": time_running / 3600,\n",
    "            \"n_gpus\": n_gpus,\n",
    "            \"gpu_hours\": time_running * n_gpus / 3600,\n",
    "            \"time_left (hours)\": time_left,\n",
    "            \"%finished\": percent_finished,\n",
    "            \"step\": current_step,\n",
    "            \"host\": run['sys/hostname']\n",
    "        }\n",
    "        \n",
    "        # Include the run specifications in the result\n",
    "        for column in run_specs.keys():\n",
    "            result[column] = run.get(column, None)\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = {\n",
    "    # 'none': None,\n",
    "    '4M': 3145728,\n",
    "    # '9M': 7077888,\n",
    "    '33M': 25165824,\n",
    "    '65M': 49152000,\n",
    "    '113M': 84934656,\n",
    "    '260M': 201326592,\n",
    "    '520M': 393216000,\n",
    "}\n",
    "\n",
    "training_lengths = {\n",
    "    # 'none': None,\n",
    "    '500M': 1907,\n",
    "    '1B': 3814,\n",
    "    '2B': 7628,\n",
    "    '4B': 15256,\n",
    "    '8B': 30512,\n",
    "    '16B': 61024,\n",
    "    '32B': 122048,\n",
    "    '64B': 244150,\n",
    "    '128B': 488300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/pmtest/llm-random/\n",
      "(320, 4342)\n",
      "https://app.neptune.ai/pmtest/llm-random/\n",
      "table downloaded\n",
      "shape: (276, 4342)\n"
     ]
    }
   ],
   "source": [
    "project = neptune.init_project(\n",
    "    project=\"pmtest/llm-random\",\n",
    "    mode=\"read-only\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\"\n",
    ")\n",
    "\n",
    "runs_table = project.fetch_runs_table(tag=[\"constrained_scaling_grid_final\"]).to_pandas()\n",
    "print(runs_table.shape)\n",
    "\n",
    "runs_table = get_neptune_table(tags=['constrained_scaling_grid_final'], negative_tags=['remove', 'remove_constrained_scaling_laws'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_hours (completed/all): 23.5/23.5\tfinished: 6/6\tmodel: 4M\tsteps: 500M\n",
      "gpu_hours (completed/all): 41.7/41.7\tfinished: 6/6\tmodel: 4M\tsteps: 1B\n",
      "gpu_hours (completed/all): 94.4/94.4\tfinished: 6/6\tmodel: 4M\tsteps: 2B\n",
      "gpu_hours (completed/all): 110.2/110.2\tfinished: 6/6\tmodel: 4M\tsteps: 4B\n",
      "gpu_hours (completed/all): 35.7/35.7\tfinished: 6/6\tmodel: 4M\tsteps: 8B\n",
      "gpu_hours (completed/all): 80.4/80.4\tfinished: 6/6\tmodel: 4M\tsteps: 16B\n",
      "gpu_hours (completed/all): 156.9/156.9\tfinished: 6/6\tmodel: 4M\tsteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 4M\tsteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 4M\tsteps: 128B\n",
      "gpu_hours (completed/all): 34.8/34.8\tfinished: 6/6\tmodel: 33M\tsteps: 500M\n",
      "gpu_hours (completed/all): 70.5/70.5\tfinished: 6/6\tmodel: 33M\tsteps: 1B\n",
      "gpu_hours (completed/all): 134.9/134.9\tfinished: 6/6\tmodel: 33M\tsteps: 2B\n",
      "gpu_hours (completed/all): 353.3/353.3\tfinished: 17/18\tmodel: 33M\tsteps: 4B\n",
      "gpu_hours (completed/all): 87.6/87.6\tfinished: 6/6\tmodel: 33M\tsteps: 8B\n",
      "gpu_hours (completed/all): 183.6/183.6\tfinished: 6/6\tmodel: 33M\tsteps: 16B\n",
      "gpu_hours (completed/all): 356.6/356.6\tfinished: 6/6\tmodel: 33M\tsteps: 32B\n",
      "gpu_hours (completed/all): 386.8/386.8\tfinished: 3/3\tmodel: 33M\tsteps: 64B\n",
      "gpu_hours (completed/all): 350.7/350.7\tfinished: 1/1\tmodel: 33M\tsteps: 128B\n",
      "gpu_hours (completed/all): 8.0/8.0\tfinished: 6/6\tmodel: 65M\tsteps: 500M\n",
      "gpu_hours (completed/all): 15.8/15.8\tfinished: 6/6\tmodel: 65M\tsteps: 1B\n",
      "gpu_hours (completed/all): 31.4/31.4\tfinished: 6/6\tmodel: 65M\tsteps: 2B\n",
      "gpu_hours (completed/all): 62.8/62.8\tfinished: 6/6\tmodel: 65M\tsteps: 4B\n",
      "gpu_hours (completed/all): 124.9/124.9\tfinished: 6/6\tmodel: 65M\tsteps: 8B\n",
      "gpu_hours (completed/all): 280.6/280.6\tfinished: 6/6\tmodel: 65M\tsteps: 16B\n",
      "gpu_hours (completed/all): 529.3/529.3\tfinished: 6/6\tmodel: 65M\tsteps: 32B\n",
      "gpu_hours (completed/all): 335.1/335.1\tfinished: 2/2\tmodel: 65M\tsteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 65M\tsteps: 128B\n",
      "gpu_hours (completed/all): 32.6/32.6\tfinished: 6/6\tmodel: 113M\tsteps: 500M\n",
      "gpu_hours (completed/all): 62.2/62.2\tfinished: 6/6\tmodel: 113M\tsteps: 1B\n",
      "gpu_hours (completed/all): 118.3/118.3\tfinished: 6/6\tmodel: 113M\tsteps: 2B\n",
      "gpu_hours (completed/all): 87.0/87.0\tfinished: 6/6\tmodel: 113M\tsteps: 4B\n",
      "gpu_hours (completed/all): 177.6/177.6\tfinished: 6/6\tmodel: 113M\tsteps: 8B\n",
      "gpu_hours (completed/all): 420.5/420.5\tfinished: 6/6\tmodel: 113M\tsteps: 16B\n",
      "gpu_hours (completed/all): 715.8/715.8\tfinished: 6/6\tmodel: 113M\tsteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 113M\tsteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 113M\tsteps: 128B\n",
      "gpu_hours (completed/all): 22.5/22.5\tfinished: 6/6\tmodel: 260M\tsteps: 500M\n",
      "gpu_hours (completed/all): 43.5/43.5\tfinished: 6/6\tmodel: 260M\tsteps: 1B\n",
      "gpu_hours (completed/all): 85.6/85.6\tfinished: 6/6\tmodel: 260M\tsteps: 2B\n",
      "gpu_hours (completed/all): 169.9/169.9\tfinished: 6/6\tmodel: 260M\tsteps: 4B\n",
      "gpu_hours (completed/all): 336.8/336.8\tfinished: 6/6\tmodel: 260M\tsteps: 8B\n",
      "gpu_hours (completed/all): 842.4/842.4\tfinished: 6/6\tmodel: 260M\tsteps: 16B\n",
      "gpu_hours (completed/all): 856.7/856.7\tfinished: 4/4\tmodel: 260M\tsteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 260M\tsteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 260M\tsteps: 128B\n",
      "gpu_hours (completed/all): 0.0/0.5\tfinished: 0/4\tmodel: 520M\tsteps: 500M\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 520M\tsteps: 1B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 520M\tsteps: 2B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 520M\tsteps: 4B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 520M\tsteps: 8B\n",
      "gpu_hours (completed/all): 585.9/585.9\tfinished: 3/3\tmodel: 520M\tsteps: 16B\n",
      "gpu_hours (completed/all): 319.4/319.4\tfinished: 1/1\tmodel: 520M\tsteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 520M\tsteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "gpu_hours: no-runs\tmodel: 520M\tsteps: 128B\n",
      "\n",
      "Used total 8766.7 GPU (A100) hours\n",
      "Used for completed runs 8766.15 GPU (A100) hours\n"
     ]
    }
   ],
   "source": [
    "total_gpu_hours = 0\n",
    "total_completed_hours = 0\n",
    "\n",
    "for model_size, model_value in model_sizes.items():\n",
    "    for training_length, training_value in training_lengths.items():\n",
    "        run_specifications = {\n",
    "            'args/model_n_active': model_value,\n",
    "            'args/n_steps': training_value,\n",
    "        }\n",
    "        df = get_training_progress_with_eta(runs_table=runs_table,\n",
    "                                            run_specs=run_specifications)\n",
    "        if df is not None:\n",
    "            gpu_hours = df['gpu_hours'].sum()\n",
    "            total_gpu_hours += gpu_hours\n",
    "            completed_runs_hours = df[df['%finished'] == 100]['gpu_hours'].sum()\n",
    "            total_completed_hours += completed_runs_hours\n",
    "            print(f\"gpu_hours (completed/all): {round(completed_runs_hours, 1)}/{round(gpu_hours, 1)}\\tfinished: {df[df['%finished'] == 100].shape[0]}/{df.shape[0]}\\tmodel: {model_size}\\tsteps: {training_length}\")\n",
    "        else:\n",
    "            print(f\"gpu_hours: no-runs\\tmodel: {model_size}\\tsteps: {training_length}\")\n",
    "\n",
    "print()\n",
    "print(f'Used total {round(total_gpu_hours, 2)} GPU (A100) hours')\n",
    "print(f'Used for completed runs {round(total_completed_hours, 2)} GPU (A100) hours')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_status_by_tags(tags, negative_tags=None, active=False):\n",
    "\n",
    "    runs_table = get_neptune_table(tags=tags, negative_tags=negative_tags, active=active)\n",
    "    print(runs_table.shape)\n",
    "\n",
    "    run_specs = {\"args/n_steps\": training_lengths['none'], \"args/model_n_active\": model_sizes['none'], \"args/expansion_rate\": None, \"sys/state\": None}\n",
    "    active = True\n",
    "\n",
    "    result = get_training_progress_with_eta(runs_table, run_specs, active=active)\n",
    "    result[\"args/model_n_active\"] = (result[\"args/model_n_active\"] / 1000000).round().astype(int)\n",
    "    result[\"time_left (d)\"] = (result[\"time_left (hours)\"] / 24).round(2)\n",
    "    # result = result[result[\"%finished\"] != 100]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/pmtest/llm-random/\n",
      "table downloaded\n",
      "shape: (3, 733)\n",
      "(3, 733)\n",
      "(3, 733)\n",
      "                ID  time_running  time_left (hours)  %finished     step  \\\n",
      "0  LLMRANDOM-16074     79905.495       82874.604006     49.088  24544.0   \n",
      "1  LLMRANDOM-16073    132897.652       26131.703734     83.568  41784.0   \n",
      "2  LLMRANDOM-16028    206926.890        8129.117067     96.220  48110.0   \n",
      "\n",
      "             host  args/n_steps  args/model_n_active  args/expansion_rate  \\\n",
      "0  164-152-24-115         50000                  679                    8   \n",
      "1         login01         50000                  679                    8   \n",
      "2         4124gs0         50000                  679                    8   \n",
      "\n",
      "  sys/state  time_left (d)  \n",
      "0    Active        3453.11  \n",
      "1    Active        1088.82  \n",
      "2    Active         338.71  \n"
     ]
    }
   ],
   "source": [
    "component_names = ['embedding_layer', 'head', 'gating', 'expert_inner_function', 'projection']\n",
    "start_ends = ['start', 'end']\n",
    "negative_tags = ['remove']\n",
    "\n",
    "uplot_medium_tags = ['relativity_paper']\n",
    "active=True\n",
    "\n",
    "# for start_end in start_ends:\n",
    "#     for component in component_names:\n",
    "#         uplot_medium_tags = ['relativity_paper', 'medium_model', 'uplot', start_end, component]\n",
    "\n",
    "#         df = get_neptune_table(tags=uplot_medium_tags, negative_tags=negative_tags)\n",
    "#         print(f'{start_end}, component: {component}, shape: {df.shape}')\n",
    "\n",
    "not_finished = exp_status_by_tags(tags=uplot_medium_tags, negative_tags=negative_tags, active=active)\n",
    "# print(not_finished.shape)\n",
    "# not_finished = not_finished[not_finished['sys/state'] != 'Active']\n",
    "print(not_finished)\n",
    "not_finished.to_csv('not_finished_relativity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
