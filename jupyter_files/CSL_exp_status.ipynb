{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune as neptune\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neptune_table(tags, negative_tags=None, active=False):\n",
    "    # Initialize the Neptune project in read-only mode\n",
    "    project = neptune.init_project(\n",
    "        project=\"pmtest/llm-random\",\n",
    "        mode=\"read-only\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMDY0ZDI5Ni05YWU3LTQyNGYtYmY4My1hZTFkY2EzYmUwMjgifQ==\",\n",
    "    )\n",
    "\n",
    "    # Fetch runs based on the active status and specified tags\n",
    "    if active:\n",
    "        runs_table = project.fetch_runs_table(tag=tags, state='active').to_pandas()\n",
    "    else:\n",
    "        runs_table = project.fetch_runs_table(tag=tags).to_pandas()\n",
    "\n",
    "    # Filter out runs with any negative tags\n",
    "    if negative_tags:\n",
    "        for neg_tag in negative_tags:\n",
    "            runs_table = runs_table[~runs_table['sys/tags'].apply(lambda tags: neg_tag in tags)]\n",
    "\n",
    "    print(f'Table downloaded\\nShape: {runs_table.shape}')\n",
    "    return runs_table\n",
    "\n",
    "\n",
    "def get_training_progress_with_eta(runs_table, run_specs=None, active=False):\n",
    "    # Apply specifications to filter runs\n",
    "    if run_specs is not None:\n",
    "        for column, value in run_specs.items():\n",
    "            if value is not None:\n",
    "                runs_table = runs_table[runs_table[column] == value]\n",
    "\n",
    "    # If no matching runs are found, return None\n",
    "    if runs_table.empty:\n",
    "        print(\"No runs found with the specified criteria.\")\n",
    "        return None\n",
    "\n",
    "    # Gather results into a list of dictionaries\n",
    "    results = []\n",
    "    for idx, run in runs_table.iterrows():\n",
    "        # Extract run details\n",
    "        exp_id = run['sys/id']\n",
    "        current_step = run[\"step\"]\n",
    "        n_steps = run[\"args/n_steps\"]\n",
    "        time_running_hours = run['sys/running_time'] / 3600\n",
    "        n_gpus = run['args/n_gpus']\n",
    "        # expansion_rate = run['args/expansion_rate']\n",
    "\n",
    "        # Calculate completion percentage\n",
    "        percent_finished = (current_step / n_steps * 100) if n_steps > 0 else 0.0\n",
    "\n",
    "        # Estimate remaining time (ETA) if progress has been made\n",
    "        time_left = None\n",
    "        if current_step > 0:\n",
    "            time_per_step = time_running_hours / current_step\n",
    "            time_left = time_per_step * (n_steps - current_step)\n",
    "\n",
    "        # Collect relevant data in a dictionary\n",
    "        result = {\n",
    "            \"ID\": exp_id,\n",
    "            # \"E\": expansion_rate,\n",
    "            \"GPU Hours\": time_running_hours * n_gpus,\n",
    "            \"running_time\": time_running_hours,\n",
    "            \"n_gpus\": n_gpus,\n",
    "            \"step\": current_step,\n",
    "            \"% Finished\": percent_finished,\n",
    "            \"Host\": run['sys/hostname'],\n",
    "            \"Time Left (h)\": time_left,\n",
    "            \"Time Left (d)\": time_left / 24,\n",
    "        }\n",
    "\n",
    "        # Include specified run parameters\n",
    "        if run_specs is not None:\n",
    "            for spec_column in run_specs.keys():\n",
    "                result[spec_column] = run.get(spec_column, None)\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Host mapping with default assignment for hosts starting with 't'\n",
    "    host_mapping = {\n",
    "        'login01': 'IDEAS',\n",
    "        'gpu01': 'IDEAS',\n",
    "        '164-152-24-115': 'writer',\n",
    "        '4124gs0': 'entropy'\n",
    "    }\n",
    "    results_df['Host'] = results_df['Host'].apply(lambda x: host_mapping.get(x, 'athena' if x.startswith('t') else 'unknown'))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def exp_status_by_tags(tags, negative_tags=None, active=False):\n",
    "    # Retrieve runs table with specified tags and exclusions\n",
    "    runs_table = get_neptune_table(tags=tags, negative_tags=negative_tags, active=active)\n",
    "    print(\"Runs table shape:\", runs_table.shape)\n",
    "\n",
    "    # Define specifications to filter runs\n",
    "    run_specs = {\n",
    "        \"args/n_steps\": None,\n",
    "        \"args/model_n_active\": None,\n",
    "        \"args/expansion_rate\": None,\n",
    "        \"sys/state\": None\n",
    "    }\n",
    "\n",
    "    # Get training progress with estimated time remaining (ETA)\n",
    "    training_progress_df = get_training_progress_with_eta(runs_table, run_specs, active=active)\n",
    "\n",
    "    # Convert model size to millions, round, and calculate time left in days\n",
    "    if training_progress_df is not None:\n",
    "        training_progress_df[\"args/model_n_active\"] = (training_progress_df[\"args/model_n_active\"] / 1_000_000).round().astype(int)\n",
    "        training_progress_df[\"Time Left (days)\"] = (training_progress_df[\"Time Left (hours)\"] / 24).round(2)\n",
    "\n",
    "    return training_progress_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = {\n",
    "    # 'none': None,\n",
    "    '4M': 3145728,\n",
    "    # '9M': 7077888,\n",
    "    '33M': 25165824,\n",
    "    '65M': 49152000,\n",
    "    '113M': 84934656,\n",
    "    '260M': 201326592,\n",
    "    '520M': 393216000,\n",
    "}\n",
    "\n",
    "training_lengths = {\n",
    "    # 'none': None,\n",
    "    '500M': 1907,\n",
    "    '1B': 3814,\n",
    "    '2B': 7628,\n",
    "    '4B': 15256,\n",
    "    '8B': 30512,\n",
    "    '16B': 61024,\n",
    "    '32B': 122048,\n",
    "    '64B': 244150,\n",
    "    '128B': 488300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/pmtest/llm-random/\n",
      "Table downloaded\n",
      "Shape: (276, 4342)\n"
     ]
    }
   ],
   "source": [
    "runs_table = get_neptune_table(tags=['constrained_scaling_grid_final'], negative_tags=['remove', 'remove_constrained_scaling_laws'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Hours (Completed/Total): 23.5/23.5\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 500M\n",
      "GPU Hours (Completed/Total): 41.7/41.7\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 1B\n",
      "GPU Hours (Completed/Total): 94.4/94.4\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 2B\n",
      "GPU Hours (Completed/Total): 110.2/110.2\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 4B\n",
      "GPU Hours (Completed/Total): 35.7/35.7\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 8B\n",
      "GPU Hours (Completed/Total): 80.4/80.4\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 16B\n",
      "GPU Hours (Completed/Total): 156.9/156.9\tFinished Runs: 6/6\tModel Size: 4M\tSteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 4M\tSteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 4M\tSteps: 128B\n",
      "GPU Hours (Completed/Total): 34.8/34.8\tFinished Runs: 6/6\tModel Size: 33M\tSteps: 500M\n",
      "GPU Hours (Completed/Total): 70.5/70.5\tFinished Runs: 6/6\tModel Size: 33M\tSteps: 1B\n",
      "GPU Hours (Completed/Total): 134.9/134.9\tFinished Runs: 6/6\tModel Size: 33M\tSteps: 2B\n",
      "GPU Hours (Completed/Total): 353.3/353.3\tFinished Runs: 17/18\tModel Size: 33M\tSteps: 4B\n",
      "GPU Hours (Completed/Total): 87.6/87.6\tFinished Runs: 6/6\tModel Size: 33M\tSteps: 8B\n",
      "GPU Hours (Completed/Total): 183.6/183.6\tFinished Runs: 6/6\tModel Size: 33M\tSteps: 16B\n",
      "GPU Hours (Completed/Total): 356.6/356.6\tFinished Runs: 6/6\tModel Size: 33M\tSteps: 32B\n",
      "GPU Hours (Completed/Total): 386.8/386.8\tFinished Runs: 3/3\tModel Size: 33M\tSteps: 64B\n",
      "GPU Hours (Completed/Total): 350.7/350.7\tFinished Runs: 1/1\tModel Size: 33M\tSteps: 128B\n",
      "GPU Hours (Completed/Total): 8.0/8.0\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 500M\n",
      "GPU Hours (Completed/Total): 15.8/15.8\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 1B\n",
      "GPU Hours (Completed/Total): 31.4/31.4\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 2B\n",
      "GPU Hours (Completed/Total): 62.8/62.8\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 4B\n",
      "GPU Hours (Completed/Total): 124.9/124.9\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 8B\n",
      "GPU Hours (Completed/Total): 280.6/280.6\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 16B\n",
      "GPU Hours (Completed/Total): 529.3/529.3\tFinished Runs: 6/6\tModel Size: 65M\tSteps: 32B\n",
      "GPU Hours (Completed/Total): 335.1/335.1\tFinished Runs: 2/2\tModel Size: 65M\tSteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 65M\tSteps: 128B\n",
      "GPU Hours (Completed/Total): 32.6/32.6\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 500M\n",
      "GPU Hours (Completed/Total): 62.2/62.2\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 1B\n",
      "GPU Hours (Completed/Total): 118.3/118.3\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 2B\n",
      "GPU Hours (Completed/Total): 87.0/87.0\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 4B\n",
      "GPU Hours (Completed/Total): 177.6/177.6\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 8B\n",
      "GPU Hours (Completed/Total): 420.5/420.5\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 16B\n",
      "GPU Hours (Completed/Total): 715.8/715.8\tFinished Runs: 6/6\tModel Size: 113M\tSteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 113M\tSteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 113M\tSteps: 128B\n",
      "GPU Hours (Completed/Total): 22.5/22.5\tFinished Runs: 6/6\tModel Size: 260M\tSteps: 500M\n",
      "GPU Hours (Completed/Total): 43.5/43.5\tFinished Runs: 6/6\tModel Size: 260M\tSteps: 1B\n",
      "GPU Hours (Completed/Total): 85.6/85.6\tFinished Runs: 6/6\tModel Size: 260M\tSteps: 2B\n",
      "GPU Hours (Completed/Total): 169.9/169.9\tFinished Runs: 6/6\tModel Size: 260M\tSteps: 4B\n",
      "GPU Hours (Completed/Total): 336.8/336.8\tFinished Runs: 6/6\tModel Size: 260M\tSteps: 8B\n",
      "GPU Hours (Completed/Total): 842.4/842.4\tFinished Runs: 6/6\tModel Size: 260M\tSteps: 16B\n",
      "GPU Hours (Completed/Total): 856.7/856.7\tFinished Runs: 4/4\tModel Size: 260M\tSteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 260M\tSteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 260M\tSteps: 128B\n",
      "GPU Hours (Completed/Total): 0.0/0.5\tFinished Runs: 0/4\tModel Size: 520M\tSteps: 500M\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 520M\tSteps: 1B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 520M\tSteps: 2B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 520M\tSteps: 4B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 520M\tSteps: 8B\n",
      "GPU Hours (Completed/Total): 585.9/585.9\tFinished Runs: 3/3\tModel Size: 520M\tSteps: 16B\n",
      "GPU Hours (Completed/Total): 319.4/319.4\tFinished Runs: 1/1\tModel Size: 520M\tSteps: 32B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 520M\tSteps: 64B\n",
      "No runs found with the specified criteria.\n",
      "GPU Hours: No runs available\tModel Size: 520M\tSteps: 128B\n",
      "\n",
      "Summary:\n",
      "Total GPU (A100) Hours Used: 8766.7\n",
      "GPU Hours for Completed Runs: 8766.15\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters and data storage\n",
    "total_gpu_hours = 0\n",
    "total_completed_hours = 0\n",
    "all_runs_df = None\n",
    "\n",
    "# Loop through each model size and training length to accumulate GPU usage\n",
    "for model_size, active_units in model_sizes.items():\n",
    "    for training_length, step_count in training_lengths.items():\n",
    "        \n",
    "        # Define run specifications for filtering\n",
    "        run_specs = {\n",
    "            'args/model_n_active': active_units,\n",
    "            'args/n_steps': step_count,\n",
    "        }\n",
    "\n",
    "        # Fetch training progress based on current run specifications\n",
    "        df = get_training_progress_with_eta(runs_table=runs_table, run_specs=run_specs)\n",
    "\n",
    "        # If runs data exists, accumulate GPU hours and add to aggregate DataFrame\n",
    "        if df is not None:\n",
    "            gpu_hours = df['GPU Hours'].sum()\n",
    "            completed_gpu_hours = df[df['% Finished'] == 100]['GPU Hours'].sum()\n",
    "            df['model'] = model_size\n",
    "            df['tokens'] = training_length  # Add descriptive columns\n",
    "\n",
    "            # Update total GPU usage counters\n",
    "            total_gpu_hours += gpu_hours\n",
    "            total_completed_hours += completed_gpu_hours\n",
    "\n",
    "            # Print summary for the current model and step count\n",
    "            print(f\"GPU Hours (Completed/Total): {round(completed_gpu_hours, 1)}/{round(gpu_hours, 1)}\\t\"\n",
    "                  f\"Finished Runs: {df[df['% Finished'] == 100].shape[0]}/{df.shape[0]}\\t\"\n",
    "                  f\"Model Size: {model_size}\\tSteps: {training_length}\")\n",
    "\n",
    "            # Concatenate data for all runs, initializing if empty\n",
    "            all_runs_df = pd.concat([all_runs_df, df], ignore_index=True) if all_runs_df is not None else df\n",
    "        \n",
    "        # Print a message if no runs are available for the given configuration\n",
    "        else:\n",
    "            print(f\"GPU Hours: No runs available\\tModel Size: {model_size}\\tSteps: {training_length}\")\n",
    "\n",
    "# Final summary of accumulated GPU hours\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total GPU (A100) Hours Used: {round(total_gpu_hours, 2)}\")\n",
    "print(f\"GPU Hours for Completed Runs: {round(total_completed_hours, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_df = all_runs_df[all_runs_df['% Finished'] == 100]\n",
    "\n",
    "all_runs_df.to_csv('plots/CSL_completed_runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique hosts: ['athena' 'IDEAS' 'entropy' 'writer']\n"
     ]
    }
   ],
   "source": [
    "filtered_df = all_runs_df[all_runs_df['Host'].str.startswith('t')]\n",
    "\n",
    "# Print all unique hosts\n",
    "unique_hosts = all_runs_df['Host'].unique()\n",
    "print(\"Unique hosts:\", unique_hosts)\n",
    "\n",
    "# If you want to display the filtered DataFrame, use:\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest model on Athena:\n",
      "GPU Hours       291.295551\n",
      "model                 260M\n",
      "tokens                 16B\n",
      "E                       32\n",
      "n_gpus                   8\n",
      "running_time     36.411944\n",
      "Name: 217, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where host is 'athena' and E is 32\n",
    "non_athena_df = all_runs_df[(all_runs_df['Host'] == 'athena') & (all_runs_df['E'] == 32)]\n",
    "\n",
    "# Sort by 'args/model_n_active' and 'args/n_steps' in descending order\n",
    "sorted_non_athena_df = non_athena_df.sort_values(by=['args/model_n_active', 'args/n_steps'], ascending=[False, False])\n",
    "\n",
    "# Find the row with the biggest model on Athena\n",
    "biggest_model_on_athena = sorted_non_athena_df.iloc[0]\n",
    "print(\"Biggest model on Athena:\")\n",
    "print(biggest_model_on_athena[['GPU Hours', 'model', 'tokens', 'E', 'n_gpus', 'running_time']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Hours for Athena (260M, < 2 days): 4832.1458016666675\n",
      "Total GPU Hours for Other: 3934.0049988888886\n",
      "Total Days of other clusters: 6.8298697897376535\n"
     ]
    }
   ],
   "source": [
    "# Convert 'args/model_n_active' to millions for easier comparison\n",
    "all_runs_df['args/model_n_active_millions'] = all_runs_df['args/model_n_active'] / 1_000_000\n",
    "\n",
    "# Filter for Athena hosts, with model size of 260M, and time running less than 48 hours\n",
    "athena_filtered_df = all_runs_df[\n",
    "    (all_runs_df['args/model_n_active'] < biggest_model_on_athena['args/model_n_active']) &\n",
    "    (all_runs_df['running_time'] < 48)\n",
    "]\n",
    "\n",
    "# Sum the GPU Hours for the filtered runs\n",
    "total_gpu_hours_athena = athena_filtered_df['GPU Hours'].sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total GPU Hours for Athena (260M, < 2 days): {total_gpu_hours_athena}\")\n",
    "\n",
    "remaining_runs_df = all_runs_df.drop(athena_filtered_df.index)\n",
    "total_gpu_hours_other = remaining_runs_df['GPU Hours'].sum()\n",
    "print(f\"Total GPU Hours for Other: {total_gpu_hours_other}\")\n",
    "print(f\"Total Days of other clusters: {total_gpu_hours_other/(24 * 8 * 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/pmtest/llm-random/\n",
      "Table downloaded\n",
      "Shape: (10, 704)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GPU Hours</th>\n",
       "      <th>running_time</th>\n",
       "      <th>n_gpus</th>\n",
       "      <th>step</th>\n",
       "      <th>% Finished</th>\n",
       "      <th>Host</th>\n",
       "      <th>Time Left (h)</th>\n",
       "      <th>Time Left (d)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLMRANDOM-19306</td>\n",
       "      <td>34.549580</td>\n",
       "      <td>4.318697</td>\n",
       "      <td>8</td>\n",
       "      <td>5879.0</td>\n",
       "      <td>11.758</td>\n",
       "      <td>athena</td>\n",
       "      <td>32.411167</td>\n",
       "      <td>1.350465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLMRANDOM-19303</td>\n",
       "      <td>48.815318</td>\n",
       "      <td>6.101915</td>\n",
       "      <td>8</td>\n",
       "      <td>7108.0</td>\n",
       "      <td>14.216</td>\n",
       "      <td>entropy</td>\n",
       "      <td>36.820952</td>\n",
       "      <td>1.534206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLMRANDOM-19238</td>\n",
       "      <td>8.298736</td>\n",
       "      <td>1.037342</td>\n",
       "      <td>8</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>2.368</td>\n",
       "      <td>entropy</td>\n",
       "      <td>42.769328</td>\n",
       "      <td>1.782055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLMRANDOM-19070</td>\n",
       "      <td>126.634329</td>\n",
       "      <td>31.658582</td>\n",
       "      <td>4</td>\n",
       "      <td>22409.0</td>\n",
       "      <td>44.818</td>\n",
       "      <td>IDEAS</td>\n",
       "      <td>38.979515</td>\n",
       "      <td>1.624146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLMRANDOM-18919</td>\n",
       "      <td>214.727124</td>\n",
       "      <td>53.681781</td>\n",
       "      <td>4</td>\n",
       "      <td>37507.0</td>\n",
       "      <td>75.014</td>\n",
       "      <td>writer</td>\n",
       "      <td>17.880569</td>\n",
       "      <td>0.745024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLMRANDOM-18918</td>\n",
       "      <td>214.766664</td>\n",
       "      <td>53.691666</td>\n",
       "      <td>4</td>\n",
       "      <td>37757.0</td>\n",
       "      <td>75.514</td>\n",
       "      <td>writer</td>\n",
       "      <td>17.409939</td>\n",
       "      <td>0.725414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LLMRANDOM-18917</td>\n",
       "      <td>221.509526</td>\n",
       "      <td>55.377381</td>\n",
       "      <td>4</td>\n",
       "      <td>39031.0</td>\n",
       "      <td>78.062</td>\n",
       "      <td>IDEAS</td>\n",
       "      <td>15.562873</td>\n",
       "      <td>0.648453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LLMRANDOM-18911</td>\n",
       "      <td>228.338371</td>\n",
       "      <td>57.084593</td>\n",
       "      <td>4</td>\n",
       "      <td>38868.0</td>\n",
       "      <td>77.736</td>\n",
       "      <td>IDEAS</td>\n",
       "      <td>16.349328</td>\n",
       "      <td>0.681222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LLMRANDOM-18903</td>\n",
       "      <td>315.469949</td>\n",
       "      <td>78.867487</td>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LLMRANDOM-18902</td>\n",
       "      <td>309.505661</td>\n",
       "      <td>77.376415</td>\n",
       "      <td>4</td>\n",
       "      <td>49572.0</td>\n",
       "      <td>99.144</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.668061</td>\n",
       "      <td>0.027836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID   GPU Hours  running_time  n_gpus     step  % Finished  \\\n",
       "0  LLMRANDOM-19306   34.549580      4.318697       8   5879.0      11.758   \n",
       "1  LLMRANDOM-19303   48.815318      6.101915       8   7108.0      14.216   \n",
       "2  LLMRANDOM-19238    8.298736      1.037342       8   1184.0       2.368   \n",
       "3  LLMRANDOM-19070  126.634329     31.658582       4  22409.0      44.818   \n",
       "4  LLMRANDOM-18919  214.727124     53.681781       4  37507.0      75.014   \n",
       "5  LLMRANDOM-18918  214.766664     53.691666       4  37757.0      75.514   \n",
       "6  LLMRANDOM-18917  221.509526     55.377381       4  39031.0      78.062   \n",
       "7  LLMRANDOM-18911  228.338371     57.084593       4  38868.0      77.736   \n",
       "8  LLMRANDOM-18903  315.469949     78.867487       4  50000.0     100.000   \n",
       "9  LLMRANDOM-18902  309.505661     77.376415       4  49572.0      99.144   \n",
       "\n",
       "      Host  Time Left (h)  Time Left (d)  \n",
       "0   athena      32.411167       1.350465  \n",
       "1  entropy      36.820952       1.534206  \n",
       "2  entropy      42.769328       1.782055  \n",
       "3    IDEAS      38.979515       1.624146  \n",
       "4   writer      17.880569       0.745024  \n",
       "5   writer      17.409939       0.725414  \n",
       "6    IDEAS      15.562873       0.648453  \n",
       "7    IDEAS      16.349328       0.681222  \n",
       "8  entropy       0.000000       0.000000  \n",
       "9  entropy       0.668061       0.027836  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_dense_table = get_neptune_table(['relativity_paper', 'large_model', 'std', 'dense'], negative_tags=['remove'])\n",
    "get_training_progress_with_eta(large_dense_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
