parent: configs/baselines/gpt/dense/llama_8b.yaml
md5_parent_hash: dc078b596473b6a036838306ef524a66
n_gpus: 16
n_nodes: 4
time: "0-02:00:00"
params:
    num_workers: 16
    data_seed: -1
    n_tokens: null
    n_steps: 1266    
    batch_size: 512
    cutoff: 512
    fsdp_enabled: true
    mixed_precision: true
    mixed_precision_dtype: bfloat16
    flash_attention: true
    fsdp_modules_to_wrap: "TransformerBlock,EmbeddingLayer,PredictionHead"
    activation_checkpointing_modules: "TransformerBlock,EmbeddingLayer,PredictionHead"
    gradient_accumulation_steps: 1
    ff_mode: vanilla
    dataset_type: c4
    learning_rate: 5e-4
    name: bs_rampup_refactor
    tags: [bs_rampup_test, rampup_refactor_pr, rampup, tokens]
    decoding_interval: 0
    save_weights_interval: 0
    logging_interval_heavy: 1000
    eval_interval: 1000
    init_type: truncated_normal
    init_scale: 1.0
